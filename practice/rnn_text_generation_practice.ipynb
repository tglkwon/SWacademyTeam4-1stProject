{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of text: 1115394 chars\n"
     ]
    }
   ],
   "source": [
    "# 바이너리 읽기\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "print(f'Len of text: {len(text)} chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique characters in the file : 65\n"
     ]
    }
   ],
   "source": [
    "# 파일 내 유니크한 문자들\n",
    "vocab = sorted(set(text))\n",
    "print(f'The unique characters in the file : {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringLoopUp -> 문자열 feature를 정수 인덱스에 매핑해주는 전처리 레이어\n",
    "# mask token -> 마스킹된 input을 나타내는 토큰. output mode가 int일때만 vocabulary에 포함되며 index는 0임\n",
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts = ['practice', 'rnn']\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')  # UTF-8 소문자로 적으면 에러남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'p', b'r', b'a', b'c', b't', b'i', b'c', b'e'], [b'r', b'n', b'n']]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids_from_chars(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[55, 57, 40, 42, 59, 48, 42, 44], [57, 53, 53]]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'practice', b'rnn'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1], dtype=int64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 (Prediction)\n",
    "# Training examples과 targets 생성\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 벡터를 문자 인덱스의 스트림으로 변환\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n",
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "tf.Tensor(\n",
      "[b'a' b'r' b'e' b' ' b'a' b'l' b'l' b' ' b'r' b'e' b's' b'o' b'l' b'v'\n",
      " b'e' b'd' b' ' b'r' b'a' b't' b'h' b'e' b'r' b' ' b't' b'o' b' ' b'd'\n",
      " b'i' b'e' b' ' b't' b'h' b'a' b'n' b' ' b't' b'o' b' ' b'f' b'a' b'm'\n",
      " b'i' b's' b'h' b'?' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'R' b'e' b's'\n",
      " b'o' b'l' b'v' b'e' b'd' b'.' b' ' b'r' b'e' b's' b'o' b'l' b'v' b'e'\n",
      " b'd' b'.' b'\\n' b'\\n' b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i'\n",
      " b'z' b'e' b'n' b':' b'\\n' b'F' b'i' b'r' b's' b't' b',' b' ' b'y' b'o'\n",
      " b'u' b' ' b'k'], shape=(101,), dtype=string)\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "tf.Tensor(\n",
      "[b'n' b'o' b'w' b' ' b'C' b'a' b'i' b'u' b's' b' ' b'M' b'a' b'r' b'c'\n",
      " b'i' b'u' b's' b' ' b'i' b's' b' ' b'c' b'h' b'i' b'e' b'f' b' ' b'e'\n",
      " b'n' b'e' b'm' b'y' b' ' b't' b'o' b' ' b't' b'h' b'e' b' ' b'p' b'e'\n",
      " b'o' b'p' b'l' b'e' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'W' b'e'\n",
      " b' ' b'k' b'n' b'o' b'w' b\"'\" b't' b',' b' ' b'w' b'e' b' ' b'k' b'n'\n",
      " b'o' b'w' b\"'\" b't' b'.' b'\\n' b'\\n' b'F' b'i' b'r' b's' b't' b' ' b'C'\n",
      " b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'L' b'e' b't' b' ' b'u' b's'\n",
      " b' ' b'k' b'i'], shape=(101,), dtype=string)\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "tf.Tensor(\n",
      "[b'l' b'l' b' ' b'h' b'i' b'm' b',' b' ' b'a' b'n' b'd' b' ' b'w' b'e'\n",
      " b\"'\" b'l' b'l' b' ' b'h' b'a' b'v' b'e' b' ' b'c' b'o' b'r' b'n' b' '\n",
      " b'a' b't' b' ' b'o' b'u' b'r' b' ' b'o' b'w' b'n' b' ' b'p' b'r' b'i'\n",
      " b'c' b'e' b'.' b'\\n' b'I' b's' b\"'\" b't' b' ' b'a' b' ' b'v' b'e' b'r'\n",
      " b'd' b'i' b'c' b't' b'?' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'N' b'o'\n",
      " b' ' b'm' b'o' b'r' b'e' b' ' b't' b'a' b'l' b'k' b'i' b'n' b'g' b' '\n",
      " b'o' b'n' b\"'\" b't' b';' b' ' b'l' b'e' b't' b' ' b'i' b't' b' ' b'b'\n",
      " b'e' b' ' b'd'], shape=(101,), dtype=string)\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "tf.Tensor(\n",
      "[b'o' b'n' b'e' b':' b' ' b'a' b'w' b'a' b'y' b',' b' ' b'a' b'w' b'a'\n",
      " b'y' b'!' b'\\n' b'\\n' b'S' b'e' b'c' b'o' b'n' b'd' b' ' b'C' b'i' b't'\n",
      " b'i' b'z' b'e' b'n' b':' b'\\n' b'O' b'n' b'e' b' ' b'w' b'o' b'r' b'd'\n",
      " b',' b' ' b'g' b'o' b'o' b'd' b' ' b'c' b'i' b't' b'i' b'z' b'e' b'n'\n",
      " b's' b'.' b'\\n' b'\\n' b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i'\n",
      " b'z' b'e' b'n' b':' b'\\n' b'W' b'e' b' ' b'a' b'r' b'e' b' ' b'a' b'c'\n",
      " b'c' b'o' b'u' b'n' b't' b'e' b'd' b' ' b'p' b'o' b'o' b'r' b' ' b'c'\n",
      " b'i' b't' b'i'], shape=(101,), dtype=string)\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "# batch\n",
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(5):\n",
    "    print(chars_from_ids(seq))\n",
    "    print(text_from_ids(seq).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list('Tensorflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input :  b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target :  b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input : ', text_from_ids(input_example).numpy())\n",
    "    print('Target : ', text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training batches 생성\n",
    "# 위에서 tf.data를 이용해서 텍스트를 manageable sequence로 변환함\n",
    "# 여기서는 데이터를 모델에 넣기 전에 섞고 batch를 적용할 것\n",
    "\n",
    "# Batch size = 64\n",
    "BATCH_SIZE = 64\n",
    "# Buffer size -> shuffle dataset\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 빌드\n",
    "# 이 모델은 3개의 레이어로 구성됨\n",
    "# 1. tf.keras.layers.Embedding : The input layer. A trainable lookup table that will map each character-ID to a vector with embedding_dim dimensions;\n",
    "# 2. tf.keras.layers.GRU : GRU\n",
    "# 3. tf.keras.layers.Dense : The output layer, with vocab_size outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model.\n",
    "\n",
    "# Length of the vocabulary in StringLookup layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN 유닛 수\n",
    "rnn_units = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screensh](./text_generation_training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "# Try the model\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, '# (batch_size, sequence_length, vocab_size)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  16896     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first example in the batch\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53, 43, 39, 56, 63, 17, 56, 19, 17, 57, 48, 58, 35, 45, 34, 22,  8,\n",
       "       55, 57, 42, 43, 30, 56,  6, 59, 50, 18, 51, 53, 30, 44, 38, 20, 42,\n",
       "       31, 57, 30, 55, 55, 32, 44,  2, 20, 20, 45, 28, 41, 13,  6, 38,  3,\n",
       "       65, 12, 54, 45,  8,  8, 52, 40, 26, 48, 46, 33, 11, 57, 44, 26,  0,\n",
       "       45, 18, 27, 28, 45, 61, 23, 42, 21, 52, 25,  3, 31, 56, 27, 13, 26,\n",
       "       15, 40, 33, 40, 48, 41, 44, 37, 65, 17, 46, 35, 43, 31,  6],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'S:\\nI know you are now, sir, a gentleman born.\\n\\nClown:\\nAy, and have been so any time these four hours'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"ndZqxDqFDrisVfUI-prcdQq'tkElnQeYGcRrQppSe GGfOb?'Y!z;of--maMigT:reM[UNK]fENOfvJcHmL!RqN?MBaTaibeXzDgVdR'\"\n"
     ]
    }
   ],
   "source": [
    "# Decode\n",
    "print('Input:\\n', text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print('Next Char Predictions:\\n', text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# optimizer와 loss func 적용\n",
    "\n",
    "# loss function, 모델이 logits을 return하기때문에 from_logits를 True로 줌\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.189608, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print('Prediction shape: ', example_batch_predictions.shape, ' # (batch_size, sequence_length, vocab_size)')\n",
    "print('Mean loss:        ', example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.99692"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새롭게 initialized된 모델은 자체적으로 너무 확신할 수 없고, \n",
    "# output logits들의 크기는 모두 비슷해야한다. \n",
    "# 위의 사항을 확인하기 위해서, \n",
    "# mean loss에 exp를 씌운 값이 ocabulary size와 거의 같은지를 확인\n",
    "# loss가 높다 -> 모델이 오답을 정답이라고 확신하고 잘못 초기화되었음을 의미\n",
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 설정\n",
    "\n",
    "# 저장 경로\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "# 이름\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 실행\n",
    "\n",
    "# EPOCHS\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 307s 2s/step - loss: 2.7185\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 294s 2s/step - loss: 1.9851\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 289s 2s/step - loss: 1.7090\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 295s 2s/step - loss: 1.5483\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 289s 2s/step - loss: 1.4481\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 287s 2s/step - loss: 1.3806\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 288s 2s/step - loss: 1.3268\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 288s 2s/step - loss: 1.2813\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 292s 2s/step - loss: 1.2400\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 297s 2s/step - loss: 1.1998\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 290s 2s/step - loss: 1.1593\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 292s 2s/step - loss: 1.1185\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 286s 2s/step - loss: 1.0747\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 290s 2s/step - loss: 1.0277\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 286s 2s/step - loss: 0.9785\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 287s 2s/step - loss: 0.9280\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 286s 2s/step - loss: 0.8757\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 288s 2s/step - loss: 0.8226\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 292s 2s/step - loss: 0.7718\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 295s 2s/step - loss: 0.7236\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "\n",
    "# 이 모델을 사용하여 텍스트를 생성하는 가장 간단한 방법\n",
    "# 반복적으로 모델을 실행할 때 모델의 내부 상태를 추적하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screensh](./text_generation_sampling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # 생성 과정에서 UNK를 막기 위해 마스크 생성\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # 각각의 bad index에 -무한대 집어넣음\n",
    "            values = [-float('inf')] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape = [len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # 문자열을 토큰 ids로 변환\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # 모델 실행\n",
    "        # predicted_logits.shape은 [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)                                     \n",
    "            \n",
    "        # 마지막 prediction만 사용\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # token ids를 문자로 변환\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # 문자와 model state를 return\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "My tell-work, sirs, let's see these burchers of my sweet tongue\n",
      "And fear on thee, for I should knock\n",
      "Sound soul: my harm it is. There is no brother; so long\n",
      "I--rugune of generus pity to my simplishment:\n",
      "Or I my love, among your love pronount by\n",
      "their beadseres. What doth he married the command\n",
      "And set thy choice be cured sons,\n",
      "But yet my mind that Richmond in their grave.\n",
      "\n",
      "LADY GREY:\n",
      "'Tis but your lord cheek to me; for I throw at a\n",
      "piece of invented man it is so much swears,\n",
      "Whomily they shall proceed.\n",
      "\n",
      "ISABELLA:\n",
      "So sleep these tedious,\n",
      "As if thou slew her brothers and how cannot\n",
      "Be for determinent?\n",
      "\n",
      "CATESBY:\n",
      "My lord?\n",
      "\n",
      "PAULINA:\n",
      "Answer it, most ownards?\n",
      "I will tell her as the found music stabs,\n",
      "Who was whether 'twas done canter in thee,\n",
      "Half-yard, wither'd rust, and lovers' territories.\n",
      "Now, soft! say'st thou forth ma-king colours!\n",
      "With old correction caves a brave death of\n",
      "Bealina.\n",
      "\n",
      "GRUMIO:\n",
      "I am a merran be,\n",
      "Do lean-the skate, of what is my presence,\n",
      "must so his unjust;\n",
      "Had thy chaire \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.2403643131256104\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 생성을 위한 반복문 실행\n",
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_' * 80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"ROMEO:\\nThere is not made.\\n\\nPETRUCHIO:\\nVirtue it,--\\n\\nPAULINA:\\nAnd, save your son\\nWill this mis-dastly title's vengeance?\\n\\nBAPTISTA:\\nFinest thou, or drum no more forthwith some Hastings, you\\nshall prosper-heart me now; something throat,\\nAnd vick for your cousin Ruture? what compla?\\n\\nBIOH:\\nHad I the truth, I say.\\n\\nGLOUCESTER:\\nI would say that is mine own to myself.\\nI come to you and hereaford spinks we forege\\nMy saken's old hate mummer'd. Did you laugh\\nHis living woe; when he stabe't?\\nOpen thy best mach! is this well? perchance, be?\\n\\nFirst Servingman:\\nWhy, very well! the duke.\\n\\nLEONTES:\\nOn yonder count!\\n\\nFirst Lord:\\nWhy shall return for colscears, Queen.\\n\\nKING EDWARD IV:\\nBut, being alone, something goodly benefit\\nWhich hence to take this wrankling sun.\\n\\nPAULI:\\nThou'rt took my daughter: I am rone, I must alone with him.\\n\\nHORTENSIO:\\nMarcius, here, that I mean not on thy words appears:\\nANd now, dy presume, beshipp at the queen's;\\nO, but our children, every steph, sacred\\nland, andwelling the rest.\\n\"\n",
      " b\"ROMEO:\\nSpark not to me, I hope he'l give you.\\n\\nMIRANDA:\\n'Sige a worldlike such as good,\\nTo know your mistress, my poor sons, most innocency,\\nA marciest law or most sweet year,\\nFor I meant with God and not choose but as long\\nTo see you sleepy, not revenge his wall,\\nOr with thy speechless man, who hath a cause to\\n't, by my trespass of Kate,\\nHis rare entire my present dust and quite, as\\nit is, because he would have eathent Petruchio!\\n\\nHASTINGS:\\nAnd lead-mind encounter makes the pentle knaves, but when we\\nEre come the Edward peace of Sicis for 't.\\n\\nPOLIXENES:\\nVery well.\\n\\nPOLIXENES:\\nBy my troth, it is more worthy gains?\\nO, my most strange drift me, O, poor souls,\\nGood ken, it dangerous.\\n\\nLADY CAPULET:\\nMarry, a bardence shall go with me.\\n3 KING HENRY VI\\n\\nWARWICK:\\nLet them assist your lordship?\\n\\nRome:\\n'Tests him;\\n'Tis done to Romeo, Claudio, than your extremess.\\n\\nWARWICK:\\nWhat, robesience he must spected a\\nFortune tyrant of an indining joys,\\nAnd never sound not scarce a tyrant forbids\\nAs thou shalt\"\n",
      " b\"ROMEO:\\n'Tis thus;\\nBut fall despite with the realm of thine;\\nUncle, your own may march not to appoint\\nFour old and banish them; I think that not in this\\nNamed in my service, nothing am nothing frails:\\nWhat, is not so I married?\\n\\nMARCIUS:\\nBeing oncentio!\\n\\nPedant:\\nI knock it.\\n\\nCAPULET:\\nDespised and criminal, lords, to me and peace\\nThose my desire and the tow'd heart for Rosaline;\\nThink that's not Romeo, and in his life,\\nWhose house of working venom to thy boon,\\nSo dispressidects, since he could not:\\nBesides, the face of you had requise his own be;\\nWhich I only to me. I dare; beseech you\\na marble weeps for very maid: at life be old!\\nAlmost in my covound not our fear;\\nFor sorrow service, raison fast, that much grant he\\ncall'd me but a mourner and many thousands that e'er the swars,\\nWhere seal'd up in heaven and we heard his prisoner\\nFor beauty than nowly begnants close:\\nWhat stars whose blood but vow-silent bids us battle.\\n\\nMENENIUS:\\nMy remedy be your company.\\n\\nPedant:\\nMy labour's in this life!\\nW\"\n",
      " b\"ROMEO:\\nSpeak, general; lest your mouthsay\\nEven whom the sail will'd cloud search: but Montague\\nThat I may bear me be thy bed to safeguity!'\\nAnd Baptista Disorar Prince,\\nUnder whose roth moved my promise, nor living\\nMost sorrow straight on fortune both:\\nThen what rein on the very heir and patricians,\\n'There's not chose you: you have ta'en guess\\nOur country's rock, so doth this castle, mad\\nAnd not admitted as the wisest: he is merch, you\\nshall give him my composing and sexants.\\n'Tis thought that Edward far my pardon from the city;\\nShe is not so, if I thone myself\\nReduked up to the Toubts stroke.\\n\\nHASTINGS:\\nOf all that I may bring thee on;\\nAnd when it is, as confess shear for.\\n\\nDUKE VINCENTIO:\\nI wish you know no roubt; not let them faith.\\n\\nBENVOLIO:\\nGood sir, and make your grace's worth askers; and be not so,\\nTo disport him off; and I\\nuntimely told me once agrought; much it he\\nupon a name of stainly burked.\\n\\nThird Servingman:\\nAy, morrow, gentle and gentlemen, or tire thy\\nwillingly compounded. I\"\n",
      " b\"ROMEO:\\nIs thy daughter?\\n\\nMARCIUS:\\nYet give me leave, and see the vice.\\nI never learn fell sink, and make my coll\\n\\nGEFON:\\nA bloody prince, more cousin, to my bonds,\\nMore worth as down of men, that teach me home\\nThat I must garley enrich your golden heies,\\nThey never send the process so my deft.\\n\\nPedant:\\nHelp, believe it, of this field,\\nThe mariners all in Flatch, and bid like realm'st,\\nWith high advantage, injured my joints pass!\\nAnd will I be avoided but by Sicil\\nYour highs?\\n\\nPROSPERO:\\nMy princess\\nWould you have miserable of a lish:\\nMy presenting boat, not restowed the wind.\\n\\nDUKE VINCENTIO:\\nNor what is leage, for I have heard it something\\nnot so discomf thine image.'\\n\\nKING RICHARD III:\\nA beggar, any man is coming hath nothing\\nBut precixing impression'd as our money?\\n\\nPRINCE EDWARD:\\nNo, sir, if you had been daughter now at poison\\npust compore.\\n\\nSecond Citizen:\\nWhy, sir, I am a villain's son,\\nAnd ask destructing on a namege;\\nIf he be could not at the Bishop's love,\\nLord Rival's death, I gave \"], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.456997871398926\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43c396205119e0bf8ba0f044c086e580415856f0dd4404af3b74e6da0571f5dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
