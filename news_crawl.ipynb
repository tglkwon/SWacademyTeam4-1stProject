{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd858497",
   "metadata": {
    "id": "cd858497",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1667650263222,
     "user_tz": -540,
     "elapsed": 289,
     "user": {
      "displayName": "지능정보 SW아카데미4조",
      "userId": "12526451333221059499"
     }
    }
   },
   "outputs": [],
   "source": [
    "from requests import get, Session, request\n",
    "from requests.compat import urlparse, urlunparse, urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552a4d07",
   "metadata": {
    "id": "552a4d07",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1667650264732,
     "user_tz": -540,
     "elapsed": 805,
     "user": {
      "displayName": "지능정보 SW아카데미4조",
      "userId": "12526451333221059499"
     }
    }
   },
   "outputs": [],
   "source": [
    "def robotParser(domain):\n",
    "    url = urlunparse(urlparse(domain)[:2] + ('',)*4)\n",
    "    url += '/robots.txt'    \n",
    "    pathEnable = dict()\n",
    "    resp = get(url)\n",
    "    if resp.status_code == 200:\n",
    "        agent = None\n",
    "        for line in resp.text.splitlines():\n",
    "            k, *v = line.split(':')\n",
    "            k = k.strip()\n",
    "            v = ':'.join(v).strip()\n",
    "            if k.lower() == 'user-agent':\n",
    "                agent = v\n",
    "                if v not in pathEnable:\n",
    "                    pathEnable[v] = dict()\n",
    "            else:\n",
    "                if k.lower() == 'allow':\n",
    "                    pathEnable[agent][v] = True\n",
    "                else:\n",
    "                    pathEnable[agent][v] = False\n",
    "    else:\n",
    "        pathEnable['*'] = True\n",
    "    return pathEnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0331e6",
   "metadata": {
    "id": "4c0331e6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1667650264732,
     "user_tz": -540,
     "elapsed": 3,
     "user": {
      "displayName": "지능정보 SW아카데미4조",
      "userId": "12526451333221059499"
     }
    }
   },
   "outputs": [],
   "source": [
    "def canFetch(pathEnable, path):\n",
    "    agent = '*'\n",
    "    path = urlparse(path).path\n",
    "    \n",
    "    if agent in pathEnable:\n",
    "        if path in pathEnable[agent]:\n",
    "            return pathEnable[agent][path]\n",
    "        else:\n",
    "            if path == '/':\n",
    "                return True\n",
    "            else:\n",
    "                return canFetch(pathEnable,\n",
    "                                '/'.join(path.split('/')[:-1]))\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syP_oa-1sf53",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1667650268270,
     "user_tz": -540,
     "elapsed": 3541,
     "user": {
      "displayName": "지능정보 SW아카데미4조",
      "userId": "12526451333221059499"
     }
    },
    "outputId": "272c3def-5228-4526-91e4-f43cd5289848"
   },
   "id": "syP_oa-1sf53",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5539a46",
   "metadata": {
    "id": "f5539a46",
    "outputId": "e65d6514-acf2-4095-9635-eaa8db2e8020",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 1\n",
      "28 2\n",
      "31 3\n",
      "30 4\n",
      "29 5\n",
      "28 6\n",
      "27 7\n",
      "32 8\n",
      "31 9\n",
      "30 10\n",
      "29 11\n",
      "28 12\n",
      "27 13\n",
      "26 14\n",
      "33 15\n",
      "32 16\n",
      "31 17\n",
      "30 18\n",
      "29 19\n",
      "28 20\n",
      "27 21\n",
      "26 22\n",
      "25 23\n",
      "30 24\n",
      "29 25\n",
      "28 26\n",
      "27 27\n",
      "26 28\n",
      "25 29\n",
      "24 30\n",
      "26 31\n",
      "25 32\n",
      "24 33\n",
      "23 34\n",
      "26 35\n",
      "25 36\n",
      "24 37\n",
      "23 38\n",
      "22 39\n",
      "24 40\n",
      "23 41\n",
      "22 42\n",
      "21 43\n",
      "23 44\n",
      "22 45\n",
      "21 46\n",
      "20 47\n",
      "22 48\n",
      "21 49\n",
      "20 50\n",
      "19 51\n",
      "20 52\n",
      "19 53\n",
      "18 54\n",
      "20 55\n",
      "19 56\n",
      "18 57\n",
      "17 58\n",
      "20 59\n",
      "19 60\n",
      "18 61\n",
      "17 62\n",
      "16 63\n",
      "19 64\n",
      "18 65\n",
      "17 66\n",
      "16 67\n",
      "15 68\n",
      "16 69\n",
      "15 70\n",
      "14 71\n",
      "14 72\n",
      "13 73\n",
      "14 74\n",
      "13 75\n",
      "12 76\n",
      "14 77\n",
      "13 78\n",
      "12 79\n",
      "11 80\n",
      "14 81\n",
      "13 82\n",
      "12 83\n",
      "11 84\n",
      "10 85\n",
      "14 86\n",
      "13 87\n",
      "12 88\n",
      "11 89\n",
      "10 90\n",
      "9 91\n",
      "12 92\n",
      "11 93\n",
      "10 94\n",
      "9 95\n",
      "8 96\n",
      "10 97\n",
      "9 98\n",
      "8 99\n",
      "7 100\n",
      "9 101\n",
      "8 102\n",
      "7 103\n",
      "6 104\n",
      "7 105\n",
      "6 106\n",
      "5 107\n",
      "6 108\n",
      "5 109\n",
      "4 110\n",
      "29 111\n",
      "33 112\n",
      "32 113\n",
      "31 114\n",
      "30 115\n",
      "29 116\n",
      "28 117\n",
      "33 118\n",
      "32 119\n",
      "31 120\n",
      "30 121\n",
      "29 122\n",
      "28 123\n",
      "27 124\n",
      "32 125\n",
      "31 126\n",
      "30 127\n",
      "29 128\n",
      "28 129\n",
      "27 130\n",
      "26 131\n",
      "31 132\n",
      "30 133\n",
      "29 134\n",
      "28 135\n",
      "27 136\n",
      "26 137\n",
      "25 138\n",
      "29 139\n",
      "28 140\n",
      "27 141\n",
      "26 142\n",
      "25 143\n",
      "24 144\n",
      "31 145\n",
      "30 146\n",
      "29 147\n",
      "28 148\n",
      "27 149\n",
      "26 150\n",
      "25 151\n",
      "24 152\n",
      "23 153\n",
      "27 154\n",
      "26 155\n",
      "25 156\n",
      "24 157\n",
      "23 158\n",
      "22 159\n",
      "28 160\n",
      "27 161\n",
      "26 162\n",
      "25 163\n",
      "24 164\n",
      "23 165\n",
      "22 166\n",
      "21 167\n",
      "21 168\n",
      "20 169\n",
      "20 170\n",
      "19 171\n",
      "22 172\n",
      "21 173\n",
      "20 174\n",
      "19 175\n",
      "18 176\n",
      "22 177\n",
      "21 178\n",
      "20 179\n",
      "19 180\n",
      "18 181\n",
      "17 182\n",
      "19 183\n",
      "18 184\n",
      "17 185\n",
      "16 186\n",
      "18 187\n",
      "17 188\n",
      "16 189\n",
      "15 190\n",
      "16 191\n",
      "15 192\n",
      "14 193\n",
      "15 194\n",
      "14 195\n",
      "13 196\n",
      "14 197\n",
      "13 198\n",
      "12 199\n",
      "13 200\n",
      "12 201\n",
      "11 202\n",
      "13 203\n",
      "12 204\n",
      "11 205\n",
      "10 206\n",
      "12 207\n",
      "11 208\n",
      "10 209\n",
      "9 210\n",
      "11 211\n",
      "10 212\n",
      "9 213\n",
      "8 214\n",
      "10 215\n",
      "9 216\n",
      "8 217\n",
      "7 218\n",
      "14 219\n",
      "13 220\n",
      "12 221\n",
      "11 222\n",
      "10 223\n",
      "9 224\n",
      "8 225\n",
      "7 226\n",
      "6 227\n",
      "10 228\n",
      "9 229\n",
      "8 230\n",
      "7 231\n",
      "6 232\n",
      "5 233\n",
      "11 234\n",
      "10 235\n",
      "9 236\n",
      "8 237\n",
      "7 238\n",
      "6 239\n",
      "5 240\n",
      "4 241\n",
      "10 242\n",
      "9 243\n",
      "8 244\n",
      "7 245\n",
      "6 246\n",
      "5 247\n",
      "4 248\n",
      "3 249\n",
      "46 250\n",
      "61 251\n",
      "60 252\n",
      "59 253\n",
      "58 254\n",
      "57 255\n",
      "56 256\n",
      "55 257\n",
      "54 258\n",
      "53 259\n",
      "52 260\n",
      "51 261\n",
      "50 262\n",
      "49 263\n",
      "48 264\n",
      "47 265\n",
      "46 266\n",
      "45 267\n",
      "62 268\n",
      "61 269\n",
      "60 270\n",
      "59 271\n",
      "58 272\n",
      "57 273\n",
      "56 274\n",
      "55 275\n",
      "54 276\n",
      "53 277\n",
      "52 278\n",
      "51 279\n",
      "50 280\n",
      "49 281\n",
      "48 282\n",
      "47 283\n",
      "46 284\n",
      "45 285\n",
      "44 286\n",
      "60 287\n",
      "59 288\n",
      "58 289\n",
      "57 290\n",
      "56 291\n",
      "55 292\n",
      "54 293\n",
      "53 294\n",
      "52 295\n",
      "51 296\n",
      "50 297\n",
      "49 298\n",
      "48 299\n",
      "47 300\n",
      "46 301\n",
      "45 302\n",
      "44 303\n",
      "43 304\n",
      "63 305\n",
      "62 306\n",
      "61 307\n",
      "60 308\n",
      "59 309\n",
      "58 310\n",
      "57 311\n",
      "56 312\n",
      "55 313\n",
      "54 314\n",
      "53 315\n",
      "52 316\n",
      "51 317\n",
      "50 318\n",
      "49 319\n",
      "48 320\n",
      "47 321\n",
      "46 322\n",
      "45 323\n",
      "44 324\n",
      "43 325\n",
      "42 326\n",
      "45 327\n",
      "44 328\n",
      "43 329\n",
      "42 330\n",
      "41 331\n",
      "43 332\n",
      "42 333\n",
      "41 334\n",
      "40 335\n",
      "41 336\n",
      "40 337\n",
      "39 338\n",
      "42 339\n",
      "41 340\n",
      "40 341\n",
      "39 342\n",
      "38 343\n",
      "40 344\n",
      "39 345\n",
      "38 346\n",
      "37 347\n",
      "39 348\n",
      "38 349\n",
      "37 350\n",
      "36 351\n",
      "38 352\n",
      "37 353\n",
      "36 354\n",
      "35 355\n",
      "37 356\n",
      "36 357\n",
      "35 358\n",
      "34 359\n",
      "38 360\n",
      "37 361\n",
      "36 362\n",
      "35 363\n",
      "34 364\n",
      "33 365\n",
      "35 366\n",
      "34 367\n",
      "33 368\n",
      "32 369\n",
      "34 370\n",
      "33 371\n",
      "32 372\n",
      "31 373\n",
      "34 374\n",
      "33 375\n",
      "32 376\n",
      "31 377\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.yna.co.kr/'\n",
    "urls = list()\n",
    "urls.append((url, 0)) # 깊이 제한\n",
    "seens = list()\n",
    "headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "\n",
    "robots = dict()\n",
    "\n",
    "categories = ['정치', '경제', '사회', '금융증권산업', '사건사고', '문화', '생활건강', 'IT과학', '북한', '국제', '스포츠', '연예']\n",
    "\n",
    "while urls:\n",
    "    # URLs Pool\n",
    "    seed = urls.pop(-1) # Queue=BFS, Stack=DFS\n",
    "    seens.append(seed[0]) # 깊이 제한\n",
    "    \n",
    "    # Robots.txt\n",
    "#     if seed not in robots:\n",
    "#         robots[seed] = robotParser(seed)\n",
    "#     rp = robots[seed]\n",
    "#     print('[Robots.txt]', seed, canFetch(rp, seed)) # True일때만,지금은무시\n",
    "    \n",
    "    # Focused Crawling\n",
    "#     if seed[1] > 2: # 자의적 => 휴리스틱\n",
    "#         continue\n",
    "        \n",
    "    resp = get(seed[0], headers=headers) # 깊이 제한\n",
    "    if resp.status_code == 200 and 'Content-Type'.lower() in resp.headers:\n",
    "                                   # content-type이 있을때만\n",
    "        if 'text/html' in\\\n",
    "           [_.strip() for _ in resp.headers['Content-Type'].split(';')]: #바꿔야함\n",
    "            dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "            aList = dom.select('a[role=menuitem]')\n",
    "            hList = dom.select('a.cluster_text_headline')\n",
    "            news = dom.select_one('#ct #contents')\n",
    "            if len(aList) > 0:\n",
    "                for el in aList[1:6]:\n",
    "                    url = el.attrs['href']\n",
    "                    nextUrl = urljoin(seed[0], url)\n",
    "                    urlParams = urlparse(nextUrl)\n",
    "\n",
    "                    # URL 체크\n",
    "                    if nextUrl not in seens and\\\n",
    "                       nextUrl not in [_[0] for _ in urls] and\\\n",
    "                       nextUrl.startswith('http'):\n",
    "                        urls.append((nextUrl, seed[1]+1))\n",
    "            if len(hList) > 0:\n",
    "                for el in hList:\n",
    "                    url = el.attrs['href']\n",
    "                    nextUrl = urljoin(seed[0], url)\n",
    "                    urlParams = urlparse(nextUrl)\n",
    "# https://n.news.naver.com/mnews/article/119/0002640090?sid=102\n",
    "                    # URL 체크\n",
    "                    if nextUrl not in seens and\\\n",
    "                       nextUrl not in [_[0] for _ in urls] and\\\n",
    "                       nextUrl.startswith('http'):\n",
    "                        urls.append((nextUrl, seed[1]+1))\n",
    "            news = dom.select_one('#ct #contents')\n",
    "            if news:\n",
    "                fileName = re.search('(\\d{10})[?]sid=(\\d{3})$', resp.url)\n",
    "                with open(\n",
    "                    '/content/drive/MyDrive/dataset/paper/{}-{}.txt'.format(fileName.group(2),\n",
    "                                              fileName.group(1)),\n",
    "                    'w', encoding='utf8') as f:\n",
    "                    f.write(news.text.strip())\n",
    "                for img in news.select('img[data-src]'):\n",
    "                    urls.append((urljoin(resp.url, img.attrs['data-src']), seed[1]+1))\n",
    "#             for el in dom.select('[src], [href]'): # [:10] 너비제한\n",
    "#                 url = el.attrs['src' if 'src' in el.attrs else 'href']\n",
    "#                 nextUrl = urljoin(seed[0], url) # 깊이 제한\n",
    "#                 urlParams = urlparse(nextUrl)\n",
    "\n",
    "#                 # URL 체크\n",
    "#                 if nextUrl not in seens and\\\n",
    "#                    nextUrl not in [_[0] for _ in urls] and\\\n",
    "#                    urlParams.netloc == 'blog.naver.com' and\\\n",
    "#                    nextUrl.startswith('http'):\n",
    "#                     # javascript, #fragment 제외시켜야 함\n",
    "#                     # Focused = 특정 도메인으로 제한\n",
    "#                     urls.append((nextUrl, seed[1]+1)) # 깊이 제한\n",
    "        else:\n",
    "            #image/jpeg\n",
    "            ext = re.search(r'image/(png|jpeg|bmp|gif)', resp.headers['Content-Type'])\n",
    "            if ext:\n",
    "#                 fileName = re.search('(\\d{8}_\\d{3})', resp.url)\n",
    "                fileName = resp.url.split('/')[-1]\n",
    "                fileName += '.'+ ext.group(1)\n",
    "                with open('/content/drive/MyDrive/dataset/news/'+fileName, 'wb') as fp:\n",
    "                    fp.write(resp.content)\n",
    "    print(len(urls), len(seens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
