{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# shakespeare corpus\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# gutenberg corpus\n",
    "fileids_ = gutenberg.fileids()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters', vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 텍스트 처리 - 벡터화 및 문자열 복구\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# get train sample\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "dataset = sequences.map(split_input_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Make train Batch\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# set model\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# train model\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# check point\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x16fc5984d60>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 ckpt 읽어서 이어서 학습하기\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 250s 1s/step - loss: 0.6438\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 239s 1s/step - loss: 0.6099\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 236s 1s/step - loss: 0.5799\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 234s 1s/step - loss: 0.5540\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 233s 1s/step - loss: 0.5320\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 232s 1s/step - loss: 0.5149\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 231s 1s/step - loss: 0.4973\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 234s 1s/step - loss: 0.4874\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 233s 1s/step - loss: 0.4741\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 239s 1s/step - loss: 0.4650\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 # 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(loss)\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# plt.plot(loss)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"ROMEO:\\n'Tis not the treaton: and the roarine hate thee\\nIn wholesome favours will hence;\\nBut if thou go, answer to me: I will go walk:\\nNot from the winter whose duspised.\\n\\nWARWICK:\\nWhy, there's the tribunes of thy news\\nBut what he did between me.\\n\\nMENENIUS:\\nComex courted to our laby-master. Then, farewell.\\n\\nGREEN:\\nHere comes the Duke of York.\\n\\nCURTISS:\\nAy, and a subter; therefore earth, and show\\nwe-loved me:\\nNay, but return'd your inflies, this, whilst I dream and sullens\\nWith thy embraces, twelve so way, look to his wife;\\nNor cherish queen and my son:\\nThou, brittle as the honourable thing,\\nEdwards such a base is the fairest creature so.\\n\\nDUCHESS OF YORK:\\nWelcome, servant; commend me to thy earth.\\nMy wounds you do impose one hast though all the water,\\nNor rate an air creeks with tears a torch\\nThou madst their gentle princes, our citizens\\nAnd persual shoulder whom from means, in truth,\\nAnd thrice replied, whom thou art not while.\\n\\nELBOW:\\nI say, sir, I will wit all:\\nUnless, it was by ripposed n\"\n",
      " b'ROMEO:\\nThe king, sir, are you yet ere now;\\nSlander with a goodly souls, to those thou shalt\\ntail; poor Merrifal dull unto William,\\nIs it not valiant nurse, which way to love,\\nShould like lose when it would not let me speak.\\n\\nBoy:\\nThink you are come to me that he usker first: but I was not move\\nyour guiltings; or else my hands\\nOf the sweet silent hours Dizadament\\nOf else prepreberess remembering how I cried our\\ncust; one must we parted with rubing friendship.\\nNow must this keen eyes owe? hear our reason\\nForbid: I stay too morrow. Ah, what should you?\\n\\nMERCUTIO:\\nThou art not none; or any things that she\\nshall kiel the waiting of mine adversaries.\\nA daglecuard in thy moods, whose princely\\ngentlemen; for our time is changed past to this present?\\nThus I can change them music law approach:\\nAnd we know me of this intends, I\\nwould revivel in thee out with mine ear close:\\nthis is the greater people, by being pup-upon\\nthe ears are happily express.\\n\\nDICHA:\\nO, Due! or else you reason?\\n\\nDUKE VINCENTIO:\\nN'\n",
      " b\"ROMEO:\\nThe king, of her most impedition\\nbegetion of my boots, or this which we intend\\nAs touch a day to-morrow, then too malace,\\nAre such'd with woe!' the estate is great; and if\\nyou purpose this prattle think, my mother,\\nLet me embrace either you must awake, and as for as sugniage,\\nHuch in the night by one silver tears. No more towards Lancaster,\\nDiamemplied.\\n\\nISABELLA:\\nJod's sittle and signior Baptista,\\nis it more than you that can lack enough all\\nwide oldness, well'd before him, and she can he\\nlies strength of summer'st royal presence thence,\\nOn earnest imperimity hix open,\\nAnd for us strong, who, runn'st to Clifford?\\nWas it not then. But, for the gods kiss our horses\\nThat empty to command my countenance, that theirs\\nAnder outrages; an out with the offent,\\nheary gidds repair, both does wed here we lose\\nthe contrary of this seclen worship's hors.\\n\\nClown:\\nWhat, have you told me I must see no son?\\n\\nFRIAR LAURENCE:\\nRomeo, come betime.\\n\\nFirst Ladyard:\\nTake thou the lazy:--why I have every oath\"\n",
      " b\"ROMEO:\\nI clear thee, with a lurking twigs,\\nWhose cares name as men right rounder,\\nTill tempers the brief of auseness of her then.\\nCamillo, this shall answer mine.\\n\\nCORIOLANUS:\\nHa!\\n\\nQUEEN ELIZABETH:\\nPlain too great noble with my lord with maid\\nWhich the nature of his curses!\\n\\nNurse:\\nWill you speak the well-denied itself? O that\\nI would not want out his new promise.\\n\\nCORIOLANUS:\\nLet them once fleet.\\nI have confined into a house of too thence,\\nLike men to peace and majesty to silence,\\nNo friends of this fortnesy and your husbands were as light.\\n\\nROMEO:\\nThou dotard! that of my sweet sweet, Clarence, thither would be closed\\nSo to this earth ammigans, which chagged\\nThe fatal canopy's eye, we have unto the king,\\nWho letters flew that you might strike to mise\\na credul that will I were afoint heavy\\nTo threaten me, brother on I am not fearfully:\\nIf I desire too roar! not for the matter,\\nI have all reason's winked innoctice,\\nWhich no less I should remain a town of Burghtable,\\nOnly the slying in my love\"\n",
      " b\"ROMEO:\\nThe keepers each his throat: I think she's colour:\\nWe are atcuent one banish'd up,\\nFor causest is enought, my gracious lord, begins the ricipt,\\nAnd not which held the happy tidins,\\nSo safely templiss of the duke!\\n\\nBENVOLIO:\\nPray you, be gone, believe me: thou villain!\\n\\nTHere Merendines:\\nHere comes the flatteries of his sister.\\n\\nTRANIO:\\nNot I, go not to me than can behalf my case\\nTo England's true think my mournings here;\\nThy mother's bonoms and revoke.\\n\\nOXFORD:\\nWilt thou demend these tenderness? has it not?\\nThe truth af are thy son is worthy work me to he fly.\\nOur shame with you; 'tis in ready, and thus;\\nStay, woman, we are bare formal honourab\\nTo bandy thousand loves on heir:\\nNo more I am, not as if this report shall mine\\neye or so, but not to his fair doubt:\\nBut of all the rest, disclandered by the house of his master.\\n\\nESCALUS:\\nName I, first leave twill wear the walls.\\n\\nBUCKINGHAM:\\nWe wait upon your grace.\\n\\nBENVOLIO:\\nThou couldst, take him to see thee. Yet, is the wonder? When we s\"], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 3.7606115341186523\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x0000016FB8E492D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    }
   ],
   "source": [
    "# model save\n",
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
