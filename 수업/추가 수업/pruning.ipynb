{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2850 - accuracy: 0.9196 - val_loss: 0.1139 - val_accuracy: 0.9692\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1163 - accuracy: 0.9664 - val_loss: 0.0819 - val_accuracy: 0.9777\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0884 - accuracy: 0.9741 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0724 - accuracy: 0.9786 - val_loss: 0.0711 - val_accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27303d774f0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d   (None, 26, 26, 12)       230       \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 13, 13, 12)       1         \n",
      " ling2d (PruneLowMagnitude)                                      \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 2028)             1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense (  (None, 10)               40572     \n",
      " PruneLowMagnitude)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# pruning은 decision tree에서 연산을 오래걸리게 하는 요소를 없애는 방법으로 쓰인 적이 있다.\n",
    "\n",
    "# Mixed precision : float32(기본)과 float16을 섞어 쓸 수 있다. GPU가 좋아야 가능\n",
    "\n",
    "# quantization : 양자화\n",
    "학습은 float32로 시키고 모델은 int까지 범위를 줄여나가는 기법\n",
    "그리고 재학습을 꼭 시킨다. 그래야 그 숫자 범위에 대해서는 더 정확한 결과가 나옴\n",
    "IoT기기는 float가 연산을 못하는 경우가 많다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# float32가 아니면 미분이 안됨 -> 모델이 만들어지지 않음\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "x = tf.Variable([1,2,3,4], dtype=tf.float32)\n",
    "with tf.GradientTape() as t:\n",
    "  y = x*x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([2., 4., 6., 8.], dtype=float32)>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.gradient(y,x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Architecture Search with reinforcement learning(NAS) : 강화학습을 활성화시킨 기법 - metamodelling\n",
    "모델 구조를 최적화하는 모델"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
